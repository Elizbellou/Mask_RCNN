{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "custom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elizbellou/Mask_RCNN/blob/main/custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5I0mhTR_UvG"
      },
      "source": [
        "\r\n"
      ],
      "id": "_5I0mhTR_UvG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N4gFiBUQQv0"
      },
      "source": [
        "\r\n"
      ],
      "id": "1N4gFiBUQQv0",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ov0SyLlRSk3",
        "outputId": "cece970a-887d-4cc0-8d21-1453ab459505"
      },
      "source": [
        ""
      ],
      "id": "9ov0SyLlRSk3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woo! You got the right kind of GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__5rAmlvj7d-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04eaead-1959-4b33-849f-d9242dd66476"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "gpu = GPUs[0]\r\n"
      ],
      "id": "__5rAmlvj7d-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=59371be7c46ef3560b11bf3d5ca2db82c4f6910315dc75549c1e8d275bc86abf\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "featured-martial"
      },
      "source": [
        ""
      ],
      "id": "featured-martial",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWnCAa1IuBG6"
      },
      "source": [
        ""
      ],
      "id": "WWnCAa1IuBG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3sNXeN_ZLr5",
        "outputId": "d2a05358-e37b-46a6-ff3f-7fb995173312"
      },
      "source": [
        "!pip install keras==2.1.6\r\n",
        "%tensorflow_version 1.15.2\r\n"
      ],
      "id": "c3sNXeN_ZLr5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.1.6 in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AREf6u-7eWhW",
        "outputId": "3a79efa2-831d-4b6a-fd5a-d1be35b90bc3"
      },
      "source": [
        "import tensorflow\r\n",
        "print(tensorflow.__version__)"
      ],
      "id": "AREf6u-7eWhW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ResD26d473",
        "outputId": "9103364c-7658-482c-b176-c243061787d6"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\r\n"
      ],
      "id": "L6ResD26d473",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeIm2ATUIUAO",
        "outputId": "a9c6d1cb-41b3-4a2a-d6e4-f3d787638618"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "NeIm2ATUIUAO",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 17 07:49:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D2hc2uLIe7W",
        "outputId": "f4567912-c76b-4edd-823a-bda5764cd5b8"
      },
      "source": [
        "import pynvml\r\n",
        "\r\n",
        "\r\n",
        "pynvml.nvmlInit()\r\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\r\n",
        "\r\n",
        "if device_name != b'Tesla T4':\r\n",
        "  raise Exception(\"\"\"\r\n",
        "    Unfortunately this instance does not have a T4 GPU.\r\n",
        "    \r\n",
        "    Please make sure you've configured Colab to request a GPU instance type.\r\n",
        "    \r\n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\r\n",
        "\r\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\r\n",
        "  \"\"\")\r\n",
        "else:\r\n",
        "  print('Woo! You got the right kind of GPU!')"
      ],
      "id": "1D2hc2uLIe7W",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woo! You got the right kind of GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwrlXjLytT_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117baec5-3b8a-4dff-aa34-5d6a030e396a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "VwrlXjLytT_a",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htfx-OFUt4pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6933147-8613-44af-e1f8-2ea1fb112b53"
      },
      "source": [
        "import os\r\n",
        "os.chdir(\"/content/drive/MyDrive/Mask_RCNN\")\r\n",
        "print(os.getcwd())"
      ],
      "id": "htfx-OFUt4pw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7O_fXHLG_hp"
      },
      "source": [
        "\r\n"
      ],
      "id": "v7O_fXHLG_hp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo4EPc9sNnvb"
      },
      "source": [
        ""
      ],
      "id": "Qo4EPc9sNnvb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axZC4ynWEsbn"
      },
      "source": [
        ""
      ],
      "id": "axZC4ynWEsbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKV5OfUu7n8"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import json\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import skimage.draw\r\n",
        "\r\n"
      ],
      "id": "ffKV5OfUu7n8",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4PE0nHsAbCl"
      },
      "source": [
        "# Root directory of the project\r\n",
        "ROOT_DIR = os.path.abspath(\"/content/drive/MyDrive/Mask_RCNN\")\r\n",
        "\r\n",
        "# Import Mask RCNN\r\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\r\n",
        "from mrcnn.config import Config\r\n",
        "import mrcnn.utils as utils\r\n",
        "from mrcnn import model as modellib\r\n",
        "\r\n",
        "\r\n",
        "# Path to trained weights file\r\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"weights.h5\")\r\n",
        "train_annotations_file = \"/content/drive/MyDrive/Mask_RCNN/dataset/train/instances.json\"\r\n",
        "train_image_dir = \"/content/drive/MyDrive/Mask_RCNN/dataset/train\"\r\n",
        "valid_annotations_file = \"/content/drive/MyDrive/Mask_RCNN/dataset/valid/instances.json\"\r\n",
        "valid_image_dir = \"/content/drive/MyDrive/Mask_RCNN/dataset/valid\"\r\n",
        "NUM_EPOCHS = 10\r\n",
        "MODEL_NAME = \"mask_v1\"\r\n",
        "# Directory to save logs and model checkpoints, if not provided\r\n",
        "# through the command line argument --logs\r\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "id": "y4PE0nHsAbCl",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "formal-judgment",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25524484-5152-4652-d661-3219ae9cfe3b"
      },
      "source": [
        "class Config(Config):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = MODEL_NAME\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 3  # Background + insulator,tower,grids\n",
        "    #All of training images are 640X512\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 640\n",
        "    PR_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    VALIDATION_STEPS = 50\n",
        "    BACKBONE = 'resnet101'\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    \n",
        "    \n",
        "    Config().display()\n"
      ],
      "id": "formal-judgment",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  640\n",
            "IMAGE_META_SIZE                16\n",
            "IMAGE_MIN_DIM                  512\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [640 640   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           mask_v1\n",
            "NUM_CLASSES                    4\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "PR_ANCHOR_SCALES               (32, 64, 128, 256, 512)\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "political-superintendent"
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class PowerlineDataset(utils.Dataset):\n",
        "\n",
        "    def load_data(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only 3 classes to add.\n",
        "        self.add_class(MODEL_NAME, 1, \"Tower\")\n",
        "        self.add_class(MODEL_NAME, 2, \"Insulator\")\n",
        "        self.add_class(MODEL_NAME, 3, \"Grids\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"valid\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \"\"\" Load the powerline dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        # Load json from file\n",
        "        json_file = open(\"/content/drive/MyDrive/Mask_RCNN/dataset/train/instances.json\")\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "        \n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        \n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['1']\n",
        "            class_name = category['Tower']\n",
        "        self.add_class(source_name, class_id, class_name) \n",
        "            \n",
        "        \n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['2']\n",
        "            class_name = category['Insulator']\n",
        "            self.add_class(source_name, class_id, class_name)  \n",
        "             \n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['3']\n",
        "            class_name = category['Grids']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
        "                return\n",
        "            \n",
        "            \n",
        "        \n",
        "        \n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "        \n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "                \n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "                 # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        \n",
        "        return mask, class_ids"
      ],
      "id": "political-superintendent",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npHQZ02ST_b"
      },
      "source": [
        ""
      ],
      "id": "1npHQZ02ST_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "charitable-flower",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "5574e00f-a94f-4339-ec8a-907213df6a78"
      },
      "source": [
        "def train(model):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = PowerlineDataset()\n",
        "    dataset_train.load_data(train_annotations_file, train_image_dir)\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = PowerlineDataset()\n",
        "    dataset_val.load_custom(valid_annotations_file, valid_image_dir)\n",
        "    dataset_val.prepare()\n",
        "\n",
        "config=Config()\n",
        "model = modellib.MaskRCNN(mode = \"training\", config = Config(), model_dir = DEFAULT_LOGS_DIR)\n",
        "model.load_weights(COCO_WEIGHTS_PATH, by_name = True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n"
      ],
      "id": "charitable-flower",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-20853c77ecd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_LOGS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m model.load_weights(COCO_WEIGHTS_PATH, by_name = True,\n\u001b[1;32m     16\u001b[0m                        exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;31m# Normalize coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             gt_boxes = KL.Lambda(lambda x: norm_boxes_graph(\n\u001b[0;32m-> 1876\u001b[0;31m                 x, K.shape(input_image)[1:3]))(input_gt_boxes)\n\u001b[0m\u001b[1;32m   1877\u001b[0m             \u001b[0;31m# 3. GT Masks (zero padded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0;31m# [batch, height, width, MAX_GT_INSTANCES]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    867\u001b[0m                               build_graph=False)\n\u001b[1;32m    868\u001b[0m       outputs = nest.map_structure(\n\u001b[0;32m--> 869\u001b[0;31m           keras_tensor.keras_tensor_from_tensor, outputs)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_set_inputs'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36mkeras_tensor_from_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36mfrom_tensor\u001b[0;34m(cls, tensor)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Fallback to the generic arbitrary-typespec KerasTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mtype_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 554\u001b[0;31m                   (value, type(value).__name__))\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv')> with type KerasTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hohqJDsGEK61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de585809-af43-4d44-89fc-05c15bd9c944"
      },
      "source": [
        " \r\n",
        " dataset_train = PowerlineDataset()\r\n",
        " dataset_val = PowerlineDataset()\r\n",
        " start_train = time.time()\r\n",
        " model.train(dataset_train, dataset_val, learning_rate = Config().LEARNING_RATE, epochs = NUM_EPOCHS, layers = 'heads')\r\n",
        " train(model)\r\n",
        " end_train = time.time()\r\n",
        " minutes = round((end_train - start_train)/60, 2)\r\n",
        " print(f'Training took {minutes} minutes')"
      ],
      "id": "hohqJDsGEK61",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Mask_RCNN/logs/mask_v120210316T1949/mask_rcnn_mask_v1_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(dataset, config, shuffle, augment, augmentation, random_rois, batch_size, detection_targets, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;31m# Increment index to pick next image. Shuffle if at the start of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0918d8061862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPowerlineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'heads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mend_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(dataset, config, shuffle, augment, augmentation, random_rois, batch_size, detection_targets, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   1808\u001b[0m             \u001b[0;31m# Log it and skip the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m             logging.exception(\"Error processing image {}\".format(\n\u001b[0;32m-> 1810\u001b[0;31m                 dataset.image_info[image_id]))\n\u001b[0m\u001b[1;32m   1811\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image_id' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_9CcK_LbO6"
      },
      "source": [
        "#save the trained model weights\r\n",
        "model.save(\"model.h5\")\r\n",
        "print(\"Saved model to disk\")"
      ],
      "id": "YA_9CcK_LbO6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxq7wCgECsv"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/P7QqBECzD6?key=0Fc8Gksff6\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "id": "toxq7wCgECsv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYORP1PpDuMa"
      },
      "source": [
        "def color_splash(image, mask):\r\n",
        "    \"\"\"Apply color splash effect.\r\n",
        "    image: RGB image [height, width, 3]\r\n",
        "    mask: instance segmentation mask [height, width, instance count]\r\n",
        "    Returns result image.\r\n",
        "    \"\"\"\r\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\r\n",
        "    # has 3 RGB channels, though.\r\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\r\n",
        "    # Copy color pixels from the original color image where mask is set\r\n",
        "    if mask.shape[-1] > 0:\r\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\r\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\r\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\r\n",
        "    else:\r\n",
        "        splash = gray.astype(np.uint8)\r\n",
        "    return splash"
      ],
      "id": "QYORP1PpDuMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joewQ1mgD0V0"
      },
      "source": [
        "def detect_and_color_splash(model, image_path=None, video_path=None):\r\n",
        "    assert image_path or video_path\r\n",
        "\r\n",
        "    # Image or video?\r\n",
        "    if image_path:\r\n",
        "        # Run model detection and generate the color splash effect\r\n",
        "        print(\"Running on {}\".format(args.image))\r\n",
        "        # Read image\r\n",
        "        image = skimage.io.imread(args.image)\r\n",
        "        # Detect objects\r\n",
        "        r = model.detect([image], verbose=1)[0]\r\n",
        "        # Color splash\r\n",
        "        splash = color_splash(image, r['masks'])\r\n",
        "        # Save output\r\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\r\n",
        "        skimage.io.imsave(file_name, splash)\r\n",
        "    elif video_path:\r\n",
        "        import cv2\r\n",
        "        # Video capture\r\n",
        "        vcapture = cv2.VideoCapture(video_path)\r\n",
        "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\r\n",
        "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\n",
        "        fps = vcapture.get(cv2.CAP_PROP_FPS)\r\n",
        "\r\n",
        "        # Define codec and create video writer\r\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\r\n",
        "        vwriter = cv2.VideoWriter(file_name,\r\n",
        "                                  cv2.VideoWriter_fourcc(*'MJPG'),\r\n",
        "                                  fps, (width, height))"
      ],
      "id": "joewQ1mgD0V0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu53fGGqD4gA"
      },
      "source": [
        " count = 0\r\n",
        "        success = True\r\n",
        "        while success:\r\n",
        "            print(\"frame: \", count)\r\n",
        "            # Read next image\r\n",
        "            success, image = vcapture.read()\r\n",
        "            if success:\r\n",
        "                # OpenCV returns images as BGR, convert to RGB\r\n",
        "                image = image[..., ::-1]\r\n",
        "                # Detect objects\r\n",
        "                r = model.detect([image], verbose=0)[0]\r\n",
        "                # Color splash\r\n",
        "                splash = color_splash(image, r['masks'])\r\n",
        "                # RGB -> BGR to save image to video\r\n",
        "                splash = splash[..., ::-1]\r\n",
        "                # Add image to video writer\r\n",
        "                vwriter.write(splash)\r\n",
        "                count += 1\r\n",
        "        vwriter.release()\r\n",
        "    print(\"Saved to \", file_name)"
      ],
      "id": "Wu53fGGqD4gA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lined-question"
      },
      "source": [
        "dataset_train = PowerlineDataset()\n",
        "dataset = dataset_train\n",
        "image_ids = np.random.mtrand.RandomState.choice(image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "id": "lined-question",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technical-hearing"
      },
      "source": [
        "    config = Config()\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=MODEL_DIR)\n",
        "\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "        "
      ],
      "id": "technical-hearing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "figured-albania"
      },
      "source": [
        "# *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "    start_train = time.time()\n",
        "model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=100,\n",
        "                layers='heads')\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "print(f'Training took {minutes} minutes')"
      ],
      "id": "figured-albania",
      "execution_count": null,
      "outputs": []
    }
  ]
}